#! /usr/bin/env python

# No Copyright (-) 2010 The Ampify Authors. This file is under the
# Public Domain license that can be found in the root LICENSE file.

"""Git review server."""

import logging
import sys

from base64 import urlsafe_b64encode
from binascii import hexlify
from datetime import datetime, timedelta
from hmac2 import HMAC
from optparse import OptionParser
from os import chdir, close, environ, getcwd, remove, urandom, write
from os.path import dirname, isdir, isfile, join, realpath
from Queue import Queue
from shutil import rmtree
from tempfile import mkstemp
from thread import start_new_thread
from time import sleep
from urllib import quote, urlencode, urlopen

from tornado.httpserver import HTTPServer
from tornado.options import enable_pretty_logging
from tornado.web import Application, HTTPError, RequestHandler
from tornado.ioloop import IOLoop

from pyutil.crypto import create_tamper_proof_string, secure_string_comparison
from pyutil.env import run_command
from pyutil.redis import Redis, set_max_connections
from simplejson import loads as decode_json, dumps as encode_json
from yaml import safe_load as decode_yaml

# ------------------------------------------------------------------------------
# Import Path
# ------------------------------------------------------------------------------

AMPIFY_ROOT = dirname(dirname(dirname(realpath(__file__))))
APP_ENGINE_SDK_PATH = join(AMPIFY_ROOT, '.appengine_python_sdk')

sys.path.insert(0, APP_ENGINE_SDK_PATH)
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'webob'))
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'fancy_urllib'))

from google.appengine.api import apiproxy_stub_map
from google.appengine.tools.appengine_rpc import HttpRpcServer
from google.appengine.ext import db
from google.appengine.ext.remote_api.remote_api_stub import (
    GetSourceName, GetUserAgent, RemoteDatastoreStub, RemoteStub
    )

class NonAuthHttpRpcServer(HttpRpcServer):
    def _DevAppServerAuthenticate(self):
        pass

# ------------------------------------------------------------------------------
# Settings
# ------------------------------------------------------------------------------

settings = dict(
    cookie_secret='insecure',
    debug=False,
    login_url='/login',
    port=8090,
    redis_socket_file='/tmp/review-server-cache.sock',
    repos=None,
    static_path='static',
    template_path='templates',
    var_path='var',
    xsrf_cookies=False
    )

Loop = IOLoop.instance()

repos = {}
repo_paths = {}

cache = None
repo_commits = {}
platforms = []
uname2platforms = {}

# ------------------------------------------------------------------------------
# Cache
# ------------------------------------------------------------------------------

Blank = object()

class CachingDict(dict):
    """A caching dict that discards its least recently used items."""

    __slots__ = '_cache_size', '_garbage_collector', '_buffer_size', 'itersort', '_clock'

    def __init__(
        self, cache_size=1000, buffer_size=None, garbage_collector=None, *args,
        **kwargs
        ):

        self._cache_size = cache_size
        self._garbage_collector = garbage_collector
        self._buffer_size = buffer_size or cache_size / 2
        self._clock = 0

        for key, value in args:
            self.__setitem__(key, value)

        for key, value in kwargs.iteritems():
            self.__setitem__(key, value)

    def __setitem__(self, key, value):
        excess = len(self) - self._cache_size - self._buffer_size + 1
        if excess > 0:
            garbage_collector = self._garbage_collector
            # @@ time against : heapq.nsmallest()
            excess = sorted(self.itersort())[:excess + self._buffer_size]
            for ex_value, ex_key in excess:
                if garbage_collector:
                    garbage_collector(ex_key, ex_value)
                del self[ex_key]

        self._clock += 1
        return dict.__setitem__(self, key, [self._clock, value])

    def __getitem__(self, key):
        if key in self:
            access = dict.__getitem__(self, key)
            self._clock += 1
            access[0] = self._clock
            return access[1]

        raise KeyError(key)

    def itersort(self):
        getitem = dict.__getitem__
        for key in self:
            yield getitem(self, key), key

    def get(self, key, default=None):
        if key in self:
            return self.__getitem__(key)

        return default

    def pop(self, key, default=Blank):

        if key in self:
            value = dict.__getitem__(self, key)[1]
            del self[key]
            return value

        if default is not Blank:
            return default

        raise KeyError(key)

    def setdefault(self, key, default):
        if key in self:
            return self.__getitem__(key)

        self.__setitem__(key, default)
        return default

    def itervalues(self):
        getitem = self.__getitem__
        for key in self:
            yield getitem(key)

    def values(self):
        return list(self.itervalues())

    def iteritems(self):
        getitem = self.__getitem__
        for key in self:
            yield key, getitem(key)

    def items(self):
        return list(self.iteritems())

    def set_cache_size(self, cache_size):

        if not isinstance(cache_size, (int, long)):
            raise ValueError("Cache size must be an integer.")

        self._cache_size = cache_size

    def get_cache_byte_size(self):
        getitem = self.__getitem__
        return sum(len(str(getitem(key))) for key in self)

# ------------------------------------------------------------------------------
# Threaded Workers
# ------------------------------------------------------------------------------

URL_QUEUE = Queue()
GIT_QUEUE = Queue()
GAE_QUEUE = Queue()

EVENTS = {}

def threaded_worker_dispatcher(queue, error_logger=None):
    while 1:
        marker, worker, args, kwargs = queue.get()
        try:
            response = worker(*args, **kwargs)
        except Exception, error:
            EVENTS[marker] = (1, error)
        else:
            EVENTS[marker] = (0, response)

class Worker(object):

    def __init__(self, queue, callback, errback, func, args, kwargs):
        self.callback = callback
        self.errback = errback
        self.marker = marker = id(self)
        queue.put((marker, func, args, kwargs))
        Loop.add_callback(self.respond)

    def respond(self):
        marker = self.marker
        if marker not in EVENTS:
            Loop.add_callback(self.respond)
            return
        error, response = EVENTS.pop(marker)
        if error:
            self.errback(response)
        else:
            self.callback(response)

def worker(queue):
    def __worker(func):
        def wrapper(*args, **kwargs):
            def __wrapper(callback, errback):
                return Worker(queue, callback, errback, func, args, kwargs)
            __wrapper.__name__ = func.__name__
            return __wrapper
        wrapper.__name__ = func.__name__
        return wrapper
    return __worker

# ------------------------------------------------------------------------------
# Async Support
# ------------------------------------------------------------------------------

class TornadoWebDispatcher(object):
    """An async process dispatcher for tornado web handler methods."""

    cb = None

    def __init__(self, gen, handler):
        self.gen = gen
        self.handler = handler
        self.callback(None)

    def callback(self, arg=None, errback=None):
        try:
            if self.cb:
                self.cb(callback=self.callback, errback=self.errback)
                self.cb = None
                return
            if errback:
                self.cb = self.gen.throw(arg)
            else:
                self.cb = self.gen.send(arg)
            Loop.add_callback(self.callback)
        except StopIteration:
            self.cb = None
            if not self.handler._finished:
                self.handler.finish()
        except Exception, error:
            self.cb = None
            if self.handler._headers_written:
                logging.error('Exception after headers written', exc_info=True)
            else:
                self.handler._handle_request_exception(error)

    def errback(self, arg):
        self.callback(arg, errback=1)

def async(method):
    def wrapper(handler, *args, **kwargs):
        handler._auto_finish = 0
        TornadoWebDispatcher(method(handler, *args, **kwargs), handler)
    wrapper.__name__ = method.__name__
    return wrapper

# ------------------------------------------------------------------------------
# Auth Support
# ------------------------------------------------------------------------------

def auth(async=False, cookie=True, xsrf=False):
    def wrapper(method):
        def __wrapper(handler, *args, **kwargs):
            handler._auto_finish = 0
            TornadoWebDispatcher(
                authenticate(
                    async, method, handler, cookie, xsrf, *args, **kwargs
                    ),
                handler
                )
        __wrapper.__name__ = method.__name__
        return __wrapper
    return wrapper

def authenticate(async, method, handler, cookie, xsrf, *args, **kwargs):
    login = handler.get_argument('login', '')
    if login:
        token = handler.get_argument('token', '')
        if login in USERS:
            if not secure_string_comparison(USERS[login], token):
                raise HTTPError(403)
        info = yield get_github_user_info(login, token)
        if not info:
            raise HTTPError(403)
        yield update_user(login, info)
        USERS[login] = token
    elif cookie:
        login = handler.get_secure_cookie('login')
        if not login:
            handler.redirect('/login')
            return
    else:
        raise HTTPError(403)
    if xsrf:
        xsrf_token = handler.get_argument('xsrf_token', '')
        if not xsrf_token:
            raise HTTPError(403)
        if login not in XSRF:
            XSRF[login] = HMAC(settings['xsrf_secret'], login).hexdigest()
        if not secure_string_comparison(XSRF[login], xsrf_token):
            raise HTTPError(403)
    if async:
        gen = method(handler, *args, **kwargs)
        resp = None
        # @@ this pipelining doesn't support catching exceptions downstream
        while 1:
            resp = yield gen.send(resp)
    else:
        method(handler, *args, **kwargs)

# ------------------------------------------------------------------------------
# Utility Functions
# ------------------------------------------------------------------------------

def git(*args, **kwargs):
    if kwargs.pop('raise_error', None):
        kwargs['retcode'] = True
        kwargs['reterror'] = True
        args = ['git'] + list(args)
        logging.info("Running: %s" % ' '.join(args))
        stdout, stderr, retcode = run_command(args, **kwargs)
        if retcode:
            raise RuntimeError(
                "Error running %s cwd=%s\n\n%s\n%s"
                % (' '.join(args), getcwd(), stdout, stderr)
                )
        return stdout
    if kwargs.pop('out', None):
        if 'exit_on_error' not in kwargs:
            kwargs['exit_on_error'] = True
        kwargs['redirect_stdout'] = False
        kwargs['redirect_stderr'] = False
        kwargs['retcode'] = True
    return run_command(['git'] + list(args), **kwargs)

def valid_review_id(id, valid=set('abcdefghijklmnopqrstuvwxyz0123456789-_')):
    if id.startswith('-') or id.startswith('_'):
        return
    for char in id:
        if char not in valid:
            return
    return id

def update_repo(name):
    chdir(repo_paths[name])
    git('remote', 'update', '-p')
    git('push', 'origin', 'upstream/master:master')

# ------------------------------------------------------------------------------
# Worker Functions
# ------------------------------------------------------------------------------

USERS = CachingDict()
XSRF = CachingDict()
EMAILS = CachingDict()

@worker(URL_QUEUE)
def get_github_user_info(login, token, keys=['email', 'gravatar_id', 'name']):
    info = dict(login=login, token=token)
    url = "http://github.com/api/v2/json/user/show/%s?%s" % (
        quote(login), urlencode(info)
        )
    try:
        data = decode_json(urlopen(url).read())['user']
    except Exception:
        return
    if 'plan' not in data:
        return
    for key in keys:
        if key in data:
            info[key] = data[key]
    return info

GAE_SERVICES = [
    'capability_service',
    'images',
    'mail',
    'memcache',
    'taskqueue',
    'urlfetch',
    'xmpp'
]

def _init_appengine(app_id, host, remote_key, secure, services=GAE_SERVICES):

    verifier = urlsafe_b64encode(urandom(24))
    mac = create_tamper_proof_string(
        'remote', verifier, duration=None, key=remote_key
        )

    path = '/.remote/%s' % mac
    environ['APPLICATION_ID'] = app_id

    server = NonAuthHttpRpcServer(
        host, None, GetUserAgent(), GetSourceName(), debug_data=False,
        secure=secure
        )

    apiproxy_stub_map.apiproxy = apiproxy_stub_map.APIProxyStubMap()
    datastore_stub = RemoteDatastoreStub(server, path)
    apiproxy_stub_map.apiproxy.RegisterStub('datastore_v3', datastore_stub)

    stub = RemoteStub(server, path)
    for service in services:
        apiproxy_stub_map.apiproxy.RegisterStub(service, stub)

def init_appengine(*args, **kwargs):
    marker = id(init_appengine)
    GAE_QUEUE.put((marker, _init_appengine, args, kwargs))
    while 1:
        if marker in EVENTS:
            break
        sleep(0.4)
    error, response = EVENTS.pop(marker)
    if error:
        raise response

@worker(GIT_QUEUE)
def apply_patch(repo, review_id, upstream, patch_file):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('am', '--abort')
    git('rebase', '--abort')
    git('clean', '-fdx', raise_error=True)
    git('reset', '--hard', 'HEAD', raise_error=True)
    for path in git('status', '--porcelain', raise_error=True).splitlines():
        if path.startswith('??'):
            path = path.split('??', 1)[1].strip()
            if isdir(path):
                rmtree(path)
    git('checkout', '-b', review_id, upstream, raise_error=True)
    git('am', patch_file, raise_error=True)
    git('push', 'origin', 'upstream/master:master', review_id, raise_error=True)

@worker(GIT_QUEUE)
def get_patch(repo, rev1, rev2):
    chdir(repo_paths[repo])
    git('diff', rev1, rev2)

def _get_new_commits(repo, start):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('push', 'origin', 'upstream/master:master', raise_error=True)
    return [commit.splitlines() for commit in git(
        'log', '--format=%H%n%an%n%ae%n%at%n%cn%n%ce%n%ct%n%s',
        '-z', '--no-color', '%s...upstream/master' % start, raise_error=True
        ).split('\x00')]

get_new_commits = worker(GIT_QUEUE)(_get_new_commits)

def _create_commits(repo, data):
    commits = []; new_commit = commits.append
    first = 1
    for (rev, an, ae, at, cn, ce, ct, subject) in data:
        if first:
            first = 0
            repo_commits[repo] = rev
        commit = Commit(key_name='%s:%s' % (repo, rev))
        commit.author = an
        commit.author_email = ae
        commit.committer = cn
        commit.committer_email = ce
        commit.committed_timestamp = datetime.fromtimestamp(int(ct))
        commit.repo = repo
        commit.subject = subject
        if ae:
            if ae in EMAILS:
                commit.user = EMAILS[ae]
            else:
                user = User.all().filter('e =', ae).get()
                if user:
                    user = user.key().name()
                    EMAILS[ae] = user
                    commit.user = user
                else:
                    commit.user = '#'
        else:
            commit.user = '#'
        commit.needed_builds = platforms
        new_commit(commit)
    db.put(commits)

create_commits = worker(GAE_QUEUE)(_create_commits)

@worker(GAE_QUEUE)
def update_user(login, info):
    user = User.get_or_insert(login)
    user.token = str(info['token'])
    user.gravatar = info['gravatar_id']
    user.name = info.get('name', '')
    user.emails = [info['email']]
    user.put()

@worker(GAE_QUEUE)
def create_slave(owner):
    slave = Slave()
    slave.owner = owner
    slave.token = hexlify(urandom(18))
    slave.put()
    return slave.key().id()

@worker(GAE_QUEUE)
def get_slaves(next=None, n=101):
    more = False
    if next:
        next = db.Key.from_path('S', int(next))
        slaves = Slave.all().filter('__key__ >= ', next).fetch(n)
    else:
        slaves = Slave.all().fetch(n)
    if not slaves:
        return [], more
    if len(slaves) == n:
        more = slaves[-1].key().id()
    slaves = slaves[:n-1]
    return slaves, more

@worker(GAE_QUEUE)
def get_slave(slave_id, next=None, n=101):
    slave_id = int(slave_id)
    slave = Slave.get_by_id(slave_id)
    if not slave:
        return
    more = False
    if next:
        next = datetime.fromtimestamp(int(next) + 1)
        builds = Build.all().filter('s =', slave_id).filter(
            'd <=', next
            ).order('-d').fetch(n)
    else:
        builds = Build.all().filter('s =', slave_id).order('-d').fetch(n)
    if not builds:
        builds = []
    else:
        if len(builds) == n:
            more = builds[-1].d.strftime('%s')
        builds = builds[:n-1]
    pending = PendingJob.all().filter('s =', slave_id).get()
    return slave, builds, pending, more

@worker(GAE_QUEUE)
def reset_slave_token(action, slave_id, user, is_admin):
    if action not in ['status', 'reset']:
        raise ValueError("Unknown action: %s" % action)
    slave = Slave.get_by_id(int(slave_id))
    if not slave:
        return
    if action == 'reset':
        if is_admin or user == slave.owner:
            slave.token = hexlify(urandom(18))
            slave.put()
            return 1
    if action == 'status':
        if is_admin:
            slave.disabled = not slave.disabled
            slave.put()
            return 1
    return 2

@worker(GAE_QUEUE)
def get_slave_job(repo, slave_id, token, uname, span=timedelta(seconds=1)):
    slave = Slave.get_by_id(slave_id)
    if (not slave) or (not secure_string_comparison(slave.token, token)):
        raise ValueError("Couldn't verify slave %s" % slave_id)
    if slave.disabled:
        raise ValueError("Slave %s has been disabled." % slave_id)
    slave.last_seen = datetime.now()
    slave.recent_platform = uname
    platform = uname2platforms.get(uname)
    if not platform:
        slave.put()
        return
    prune = PendingJob.all().filter('d <=', datetime.now() - span).fetch(100)
    if prune:
        db.run_in_transaction(prune_pending_jobs, [ob.key() for ob in prune])
    review = Review.all().filter('n =', platform).filter('r =', repo).filter(
        'g =', 'test'
        ).get()
    commit = Commit.all().filter('n =', platform).filter('r =', repo).get()
    commits = Commit.all().fetch(100)
    if review and commit:
        if review.d >= commit.d:
            parent = review
        else:
            parent = commit
    elif review:
        parent = review
        type = 'review'
    elif commit:
        parent = commit
        type = 'commit'
    else:
        slave.put()
        return
    result = []
    parent_key = parent.key()
    db.run_in_transaction(create_job, parent_key, result, slave_id, platform)
    if not result:
        slave.working = False
        slave.put()
        return
    slave.working = True
    slave.put()
    if type == 'commit':
        return parent_key.name().split(':')[1]
    review = parent_key.parent().name().split(':')
    return "%s/%s/%s" % (review[1], review[2], parent_key.id())

def prune_pending_jobs(keys):
    jobs = db.get(keys)
    parent_keys = [key.parent() for key in keys]
    parents = db.get(parent_keys)
    to_save = []; save = to_save.append
    for i in range(len(jobs)):
        platform = jobs[i].build_platform
        parent = parents[i]
        if not ((platform in parent.passed_builds) or
            (platform in parent.failed_builds) or
            (platform in parent.needed_builds)):
            parent.needed_builds.append(platform)
            save(parent)
    db.delete(keys)
    db.put(to_save)

def create_job(key, result, slave_id, platform):
    parent = db.get(key)
    if platform not in parent.needed_builds:
        return
    parent.needed_builds.remove(platform)
    job = PendingJob(parent=parent)
    job.slave = slave_id
    job.build_platform = platform
    db.put([parent, job])
    result.append(1)

@worker(GAE_QUEUE)
def create_build(
    slave_id, token, repo, revision, uname, platform, executed, payload,
    timings, traceback, has_failure
    ):
    slave = Slave.get_by_id(slave_id)
    if (not slave) or (not secure_string_comparison(slave.token, token)):
        raise ValueError("Couldn't verify slave %s" % slave_id)
    if slave.disabled:
        raise ValueError("Slave %s has been disabled." % slave_id)
    target = db.get(get_key_for_version(repo, revision))
    if not target:
        raise ValueError("Unknown revision %r for %s" % (revision, repo))
    build = Build()
    build.has_failure = has_failure
    build.executed = executed
    build.uname = uname
    build.build_platform = platform
    build.repo = repo
    build.slave = slave_id
    build.version = revision
    slave.last_seen = datetime.now()
    slave.recent_platform = uname
    slave.working = False
    slave.jobs_done += 1
    db.put([build, slave])
    data = BuildData(key_name='d', parent=build)
    if traceback:
        data.traceback = True
        data.payload = payload
    else:
        data.payload = encode_json(payload)
    data.timings = timings
    db.put(data)
    db.run_in_transaction(
        update_build_target, target.key(), platform, has_failure
        )
    return build.key().id()

def update_build_target(target, platform, has_failure):
    target = db.get(target)
    while platform in target.needed_builds:
        target.needed_builds.remove(platform)
    if has_failure:
        target.has_failure = True
        if platform not in target.failed_builds:
            target.failed_builds.append(platform)
    else:
        if platform not in target.passed_builds:
            target.passed_builds.append(platform)
    if (not target.needed_builds) and target.stage == 'test':
        target.stage = 'tested'
    db.put(target)

def get_key_for_version(repo, version, create_key=db.Key.from_path):
    if '/' in version:
        user, issue, id = version.split('/')
        parent = create_key('Q', '%s:%s:%s' % (repo, user, issue))
        return create_key('R', int(id), parent=parent)
    return create_key('G', '%s:%s' % (repo, version))

@worker(GAE_QUEUE)
def db_get(key):
    return db.get(key)

@worker(GAE_QUEUE)
def get_build_data(build_id):
    build_id = int(build_id)
    build = Build.get_by_id(build_id)
    if not build:
        return
    build_key = build.key()
    data, target = db.get([
        db.Key.from_path('D', 'd', parent=build_key),
        get_key_for_version(build.repo, build.version)
        ])
    rebuild_state = uname2platforms.get(build.uname, None)
    if rebuild_state:
        if rebuild_state in target.needed_builds:
            rebuild_state = 1
        else:
            rebuild_state = 2
    return build, data, rebuild_state

def _rebuild(target_key, platform, result):
    target = db.get(target_key)
    if platform in target.needed_builds:
        return
    target.needed_builds.append(platform)
    while platform in target.passed_builds:
        target.passed_builds.remove(platform)
    while platform in target.failed_builds:
        target.failed_builds.remove(platform)
    if not target.failed_builds:
        target.has_failure = False
    target.put()
    result.append(1)

@worker(GAE_QUEUE)
def rebuild(repo, version, platform):
    target_key = get_key_for_version(repo, version)
    result = []
    db.run_in_transaction(_rebuild, target_key, platform, result)
    if result:
        return 1

# ------------------------------------------------------------------------------
# Datastore Models
# ------------------------------------------------------------------------------

class A(db.Model): # normal id; parent = Review
    user = db.StringProperty(name='u')
    stage = db.StringProperty(name='g')
    d = db.DateTimeProperty(auto_now_add=True)

Appraisal = A

class B(db.Model): # normal id
    repo = db.StringProperty(name='r')
    slave = db.IntegerProperty(name='s')
    version = db.StringProperty(name='v')
    build_platform = db.StringProperty(name='b')
    uname = db.StringProperty(name='u')
    executed = db.StringListProperty(name='e')
    has_failure = db.BooleanProperty(name='h', default=False)
    d = db.DateTimeProperty(auto_now_add=True)

Build = B

class C(db.Model): # normal id; parent = Review
    user = db.StringProperty(name='u')
    text = db.TextProperty(name='t')
    version = db.StringProperty(name='v')
    line = db.IntegerProperty(name='l', default=0)
    file = db.StringProperty(name='f', default='')
    d = db.DateTimeProperty(auto_now_add=True)

Comment = C

class D(db.Model): # normal id; parent = Build
    traceback = db.BooleanProperty(name='e', default=False)
    payload = db.TextProperty('p')
    timings = db.ListProperty(int, name='t', indexed=False)

BuildData = D

class G(db.Model): # id = <repo>:<git-revision>
    author = db.StringProperty(name='a')
    author_email = db.StringProperty(name='b')
    committer = db.StringProperty(name='c')
    committer_email = db.StringProperty(name='e')
    committed_timestamp = db.DateTimeProperty(name='t')
    repo = db.StringProperty(name='r')
    subject = db.TextProperty(name='s')
    needed_builds = db.StringListProperty(name='n')
    passed_builds = db.StringListProperty(name='p', indexed=False)
    failed_builds = db.StringListProperty(name='f', indexed=False)
    has_failure = db.BooleanProperty(name='h', default=False)
    user = db.StringProperty(name='u') # #unknown
    d = db.DateTimeProperty(auto_now_add=True)
    m = db.DateTimeProperty(auto_now=True)

Commit = G

class P(db.Model): # normal id; parent = Commit or Review
    slave = db.IntegerProperty(name='s')
    build_platform = db.StringProperty(name='b')
    d = db.DateTimeProperty(auto_now_add=True)

PendingJob = P

class Q(db.Model): # id = <repo>:<user>:<issue>
    cc = db.StringListProperty(name='c')
    latest = db.IntegerProperty(name='l', default=0)

ReviewBase = Q

class R(db.Model): # id = incrementing integer; parent = ReviewBase
    subject = db.TextProperty(name='s')
    repo = db.StringProperty(name='r')
    upstream_revision = db.StringProperty(name='i')
    stage = db.StringProperty(name='g', default='pending')
    needed_builds = db.StringListProperty(name='n')
    passed_builds = db.StringListProperty(name='p', indexed=False)
    failed_builds = db.StringListProperty(name='f', indexed=False)
    has_failure = db.BooleanProperty(name='h', default=False)
    user = db.StringProperty(name='u')
    d = db.DateTimeProperty(auto_now_add=True)
    m = db.DateTimeProperty(auto_now=True)

Review = R

class S(db.Model): # normal id
    disabled = db.BooleanProperty(name='d', default=False)
    working = db.BooleanProperty(name='w', default=False)
    jobs_done = db.IntegerProperty(name='j', default=0)
    last_seen = db.DateTimeProperty(name='l')
    owner = db.StringProperty(name='o')
    recent_platform = db.StringProperty(name='r')
    token = db.StringProperty(name='t')

Slave = S

class U(db.Model): # key = github username
    name = db.StringProperty(name='n')
    emails = db.StringListProperty(name='e')
    gravatar = db.StringProperty(name='g')
    last_seen = db.DateTimeProperty(name='l', auto_now=True)
    token = db.StringProperty(name='t')
    d = db.DateTimeProperty(auto_now_add=True)

User = U

# ------------------------------------------------------------------------------
# Handlers
# ------------------------------------------------------------------------------

class BaseHandler(RequestHandler):

    cache = None
    title = None

    def get_current_user(self):
        return self.get_secure_cookie('login')

    def is_admin_user(self):
        return self.current_user in settings['admins']

    def display(self, template, **kwargs):
        if 'errmsg' not in kwargs:
            kwargs['errmsg'] = None
        kwargs['is_admin'] = self.is_admin_user()
        user = self.current_user
        if user:
            if user not in XSRF:
                XSRF[user] = HMAC(settings['xsrf_secret'], user).hexdigest()
            kwargs['xsrf_token'] = XSRF[user]
        else:
            kwargs['xsrf_token'] = None
        if template:
            content = self.render_string(template + '.html', **kwargs)
        else:
            content = ''
        self.render('site.html', content=content, title=self.title, **kwargs)

    def errmsg(self, errmsg):
        self.render('site.html', content='', errmsg=errmsg, title=self.title)

    def get(self):
        self.errmsg("Not implemented yet.")

class RootHandler(BaseHandler):

    def get(self):
        self.redirect('/activity')

class ActivityHandler(BaseHandler):

    def get(self):
        if not repos:
            self.errmsg('No repositories configured.')
            return
        self.display('home', repos=repos)

class DashboardHandler(BaseHandler):
    pass

class ReviewHandler(BaseHandler):

    def get(self):
        from random import random
        uname = self.get_argument('uname')
        repo_id = self.get_argument('repo_id')
        self.set_header('Content-Type', 'text/plain')
        if random() > 0.5:
            self.write('tav/ampify/master')
        else:
            self.write('//')

    @auth(async=True)
    def post(self):

        get = self.get_argument
        id = get('id')
        if not valid_review_id(id):
            self.write("Invalid characters in the review id: %s" % id)

        login = get('login')
        repo = get('repo')
        patch = get('patch')
        upstream = get('upstream')
        message = get('message', '')
        revision = get('revision')

        cc = get('cc', '')
        if cc:
            cc = decode_json(cc)
        else:
            cc = []

        login_id_prefix = '%s/%s' % (login, id)
        issue_number = 2
        review_id = '%s/%s/%s' % (login, id, issue_number)

        # existing_review_id = yield db.get(revision)
        # if existing_review_id:
        #     self.write(
        #         "This revision has already been submitted for review as %s."
        #         % existing_review_id
        #     )
        #     return

        fd, patch_file = mkstemp('-review-patch')
        write(fd, patch.encode('utf-8'))
        close(fd)

        yield apply_patch(repo, review_id, upstream, patch_file)

        self.write('OK %s' % review_id)
        #remove(patch_file)

class ReviewsHandler(BaseHandler):
    pass

class BuildsHandler(BaseHandler):
    pass

class BuildHandler(BaseHandler):

    @async
    def post(self, has_failure=False):
        get = self.get_argument
        revision = get('revision')
        uname = get('uname')
        repo = get('repo')
        slave_id = get('slave_id')
        token = get('token')
        data = get('data')
        try:
            slave_id = int(slave_id)
        except Exception:
            self.write("Invalid slave id: %r" % get('slave'))
            return
        try:
            data = decode_json(data)
        except Exception, err:
            self.write("Error decoding build data: %s" % err)
            return
        if 'traceback' in data:
            traceback = 1
            payload = data['traceback']
            timings = []
            executed = []
            has_failure = True
        else:
            traceback = 0
            executed = data['executed']
            stderr = []; add_stderr = stderr.append
            stdout = []; add_stdout = stdout.append
            timings = []; add_timing = timings.append
            payload = [stderr, stdout]
            for item in executed:
                add_timing(data['%s|time' % item])
                add_stderr(data.get('%s|stderr' % item, None))
                out = data.get('%s|stdout' % item, None)
                add_stdout(out)
                if out:
                    has_failure = True
        platform = uname2platforms.get(uname)
        build = yield create_build(
            slave_id, token, repo, revision, uname, platform, executed, payload,
            timings, traceback, has_failure
            )
        self.write('OK %s' % build)

class BuildDetailsHandler(BaseHandler):

    @async
    def get(self, build_id):
        build_data = yield get_build_data(build_id)
        if not build_data:
            self.errmsg("No records found for build %s" % build_id)
            return
        build, data, rebuild_state = build_data
        traceback = timings = stderr = stdout = None
        if data:
            if data.traceback:
                traceback = data.payload
            else:
                timings = data.timings
                stderr, stdout = decode_json(data.payload)
        self.display(
            'builddetails', build_id=build_id, build=build, traceback=traceback,
            timings=timings, stdout=stdout, stderr=stderr, data=data,
            rebuild_state=rebuild_state, platforms=uname2platforms
            )

class JobHandler(BaseHandler):

    @async
    def get(self):
        self.set_header('Content-Type', 'text/plain')
        get = self.get_argument
        uname = get('uname')
        repo = get('repo')
        slave_id = get('slave_id')
        token = get('token')
        try:
            slave_id = int(slave_id)
        except Exception:
            self.write("Invalid slave id: %r" % get('slave'))
            return
        try:
            job = yield get_slave_job(repo, slave_id, token, uname)
        except ValueError, err:
            self.write(repr(err))
            return
        self.write('OK ')
        if job:
            self.write(job)
        else:
            self.write('')

class ChartsHandler(BaseHandler):
    pass

class LoginHandler(BaseHandler):

    title = 'login'

    def get(self):
        self.display('login')

    @async
    def post(self):
        login = self.get_argument('login', "")
        token = self.get_argument('token', "")
        info = yield get_github_user_info(login, token)
        if not info:
            self.display('login', errmsg="Invalid Login.")
            return
        yield update_user(login, info)
        USERS[login] = token
        self.set_secure_cookie('login', login)
        self.redirect('/')

class LogoutHandler(BaseHandler):

    def get(self):
        self.clear_cookie('login')
        return_to = self.get_argument('return_to', '')
        if return_to:
            self.redirect(return_to)
        else:
            self.redirect('/')

class SlavesHandler(BaseHandler):

    title = 'slaves'

    @async
    def get(self):
        next = self.get_argument('next', '')
        slaves, more = yield get_slaves(next)
        self.display(
            'slaves', slaves=slaves, platforms=uname2platforms, more=more
            )

    @auth(async=True, xsrf=True)
    def post(self):
        slave_id = yield create_slave(self.current_user)
        self.redirect('/slave/%s' % slave_id)

class SlaveHandler(BaseHandler):

    title = 'slave'

    @async
    def get(self, slave_id):
        next = self.get_argument('next', '')
        slave_data = yield get_slave(slave_id, next)
        if not slave_data:
            self.errmsg("No records found for slave %s" % slave_id)
            return
        slave, builds, pending, more = slave_data
        show_token = self.is_admin_user() or (self.current_user == slave.owner)
        self.display(
            'slave', slave_id=slave_id, slave=slave, show_token=show_token,
            builds=builds, more=more, pending=pending
            )

    @auth(async=True, xsrf=True)
    def post(self, slave_id):
        action = self.get_argument('action', '')
        retcode = yield reset_slave_token(
            action, slave_id, self.current_user, self.is_admin_user()
            )
        if not retcode:
            self.errmsg("Couldn't find a record for slave %s." % slave_id)
            return
        if retcode == 2:
            self.errmsg("You're not authorised for this action.")
            return
        self.redirect('/slave/%s' % slave_id)

class PostReceiveHandler(BaseHandler):

    @async
    def post(self):
        repo = self.get_argument('repo')
        commits = yield get_new_commits(repo, repo_commits[repo])
        yield create_commits(repo, commits)
        self.write('OK')

    get = post

class RebuildHandler(BaseHandler):

    @auth(async=True, xsrf=True)
    def post(self):
        get = self.get_argument
        repo = get('repo')
        version = get('version')
        platform = get('platform')
        build_id = get('build_id')
        if platform not in platforms:
            self.errmsg("%s is not supported atm." % platform)
            return
        retval = yield rebuild(repo, version, platform)
        self.redirect('/build/%s' % build_id)

# ------------------------------------------------------------------------------
# Main Runner
# ------------------------------------------------------------------------------

def main(argv=None):

    argv = argv or sys.argv[1:]
    op = OptionParser(usage="Usage: %prog [config.yaml]", version="0.1")

    op.add_option('--dev', action='store_true', help="enable dev mode")
    options, args = op.parse_args(argv)

    if args:
        config_path = args[0]
        config_file = open(config_path, 'rb')
        config_data = config_file.read()
        config_file.close()
        config = decode_yaml(config_data)
        if not config:
            print "ERROR: Couldn't find any config data in %s" % config_path
            sys.exit(1)
    else:
        config = {}

    settings.update(config)
    cwd = realpath(getcwd())

    if options.dev:
        settings['debug'] = True
        cwd = dirname(realpath(__file__)) # @@ to support autoreload

    for key in ['static_path', 'template_path', 'var_path']:
        path = join(cwd, settings[key])
        if not isdir(path):
            print "ERROR: Please create the %s: %s" % (key, path)
            sys.exit(1)
        settings[key] = path

    repo_home = settings['repo_home'] = join(settings['var_path'], 'repos')
    if not isdir(repo_home):
        print "ERROR: Please create %s" % repo_home
        sys.exit(1)

    logging.getLogger().setLevel(logging.INFO)
    enable_pretty_logging()

    github_account = settings['github_account']

    _repos = settings['repos']
    if _repos:
        for repo in _repos:
            repos[repo] = tuple(_repos[repo])
            repo_paths[repo] = repo_path = join(repo_home, repo)
            if options.dev:
                continue
            chdir(repo_home)
            if not isdir(repo_path):
                review_url = 'git@github.com:%s/%s.git' % (github_account, repo)
                git('clone', review_url, out=True)
            chdir(repo_path)
            if not git('config', 'remote.upstream.url', exit_on_error=False):
                upstream_url = 'https://github.com/%s/%s.git' % repos[repo]
                git('remote', 'add', 'upstream', upstream_url)

    application = Application([
        (r"/dashboard", DashboardHandler),
        (r"/charts", ChartsHandler),
        (r"/reviews", ReviewsHandler),
        (r"/review", ReviewHandler),
        (r"/builds", BuildsHandler),
        (r"/build/([0-9]+)", BuildDetailsHandler),
        (r"/build", BuildHandler),
        (r"/job", JobHandler),
        (r"/logout", LogoutHandler),
        (r"/login", LoginHandler),
        (r"/slave/([0-9]+)", SlaveHandler),
        (r"/slaves", SlavesHandler),
        (r"/activity", ActivityHandler),
        (r"/post-receive", PostReceiveHandler),
        (r"/rebuild", RebuildHandler),
        (r"/", RootHandler),
    ], **settings)

    port = settings['port']
    http_server = HTTPServer(application)
    http_server.listen(port)

    uname2platforms.update(settings['platforms'])
    for platform in uname2platforms.values():
        if platform not in platforms:
            platforms.append(platform)

    set_max_connections(50)
    def cache_init(ipc=settings['redis_socket_file']):
        return Redis(unix_socket=ipc)

    global cache
    cache = cache_init

    for queue in [URL_QUEUE, GIT_QUEUE, GAE_QUEUE]:
        start_new_thread(threaded_worker_dispatcher, (queue,))

    logging.info("Connecting to App Engine Server at %s" % settings['gae_host'])
    init_appengine(
        settings['gae_app_id'], settings['gae_host'],
        settings['gae_remote_key'], settings['gae_secure']
        )

    for repo in repos:
        logging.info("Storing commit data for %s" % repo)
        commit = Commit.all().filter('r =', repo).get()
        if commit:
            repo_commits[repo] = commit.key().name().split(':')[1]
        else:
            commits = _get_new_commits(repo, 'upstream/master^')
            _create_commits(repo, commits)

    logging.info("The git review server is listening on port %d ..." % port)
    Loop.start()

# ------------------------------------------------------------------------------
# Self Runner
# ------------------------------------------------------------------------------

if __name__ == '__main__':
    main()

# <img src="http://www.gravatar.com/avatar/%s" />
