#! /usr/bin/env python

# No Copyright (-) 2010 The Ampify Authors. This file is under the
# Public Domain license that can be found in the root LICENSE file.

"""Git review server."""

import logging
import sys

from base64 import urlsafe_b64encode
from binascii import hexlify
from optparse import OptionParser
from os import chdir, close, environ, getcwd, remove, urandom, write
from os.path import dirname, isdir, isfile, join, realpath
from Queue import Queue
from shutil import rmtree
from tempfile import mkstemp
from thread import start_new_thread
from time import sleep
from urllib import quote, urlencode, urlopen

from tornado.httpserver import HTTPServer
from tornado.web import Application, HTTPError, RequestHandler
from tornado.ioloop import IOLoop

from pyutil.crypto import create_tamper_proof_string
from pyutil.env import run_command
from pyutil.redis import Redis, set_max_connections
from simplejson import loads as decode_json, dumps as encode_json
from yaml import safe_load as decode_yaml

# ------------------------------------------------------------------------------
# Import Path
# ------------------------------------------------------------------------------

AMPIFY_ROOT = dirname(dirname(dirname(realpath(__file__))))
APP_ENGINE_SDK_PATH = join(AMPIFY_ROOT, '.appengine_python_sdk')

sys.path.insert(0, APP_ENGINE_SDK_PATH)
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'webob'))

from google.appengine.api import apiproxy_stub_map
from google.appengine.tools.appengine_rpc import HttpRpcServer
from google.appengine.ext import db
from google.appengine.ext.remote_api.remote_api_stub import (
    GetSourceName, GetUserAgent, RemoteDatastoreStub, RemoteStub
    )

class NonAuthHttpRpcServer(HttpRpcServer):
    def _DevAppServerAuthenticate(self):
        pass

# ------------------------------------------------------------------------------
# Settings
# ------------------------------------------------------------------------------

settings = dict(
    cookie_secret='insecure',
    debug=False,
    login_url='/login',
    port=8090,
    redis_socket_file='/tmp/review-server-cache.sock',
    repos=None,
    static_path='static',
    template_path='templates',
    var_path='var',
    xsrf_cookies=False
    )

Loop = IOLoop.instance()

repos = {}
repo_paths = {}

cache = None

# ------------------------------------------------------------------------------
# Cache
# ------------------------------------------------------------------------------

Blank = object()

class CachingDict(dict):
    """A caching dict that discards its least recently used items."""

    __slots__ = '_cache_size', '_garbage_collector', '_buffer_size', 'itersort', '_clock'

    def __init__(
        self, cache_size=1000, buffer_size=None, garbage_collector=None, *args,
        **kwargs
        ):

        self._cache_size = cache_size
        self._garbage_collector = garbage_collector
        self._buffer_size = buffer_size or cache_size / 2
        self._clock = 0

        for key, value in args:
            self.__setitem__(key, value)

        for key, value in kwargs.iteritems():
            self.__setitem__(key, value)

    def __setitem__(self, key, value):
        excess = len(self) - self._cache_size - self._buffer_size + 1
        if excess > 0:
            garbage_collector = self._garbage_collector
            # @@ time against : heapq.nsmallest()
            excess = sorted(self.itersort())[:excess + self._buffer_size]
            for ex_value, ex_key in excess:
                if garbage_collector:
                    garbage_collector(ex_key, ex_value)
                del self[ex_key]

        self._clock += 1
        return dict.__setitem__(self, key, [self._clock, value])

    def __getitem__(self, key):
        if key in self:
            access = dict.__getitem__(self, key)
            self._clock += 1
            access[0] = self._clock
            return access[1]

        raise KeyError(key)

    def itersort(self):
        getitem = dict.__getitem__
        for key in self:
            yield getitem(self, key), key

    def get(self, key, default=None):
        if key in self:
            return self.__getitem__(key)

        return default

    def pop(self, key, default=Blank):

        if key in self:
            value = dict.__getitem__(self, key)[1]
            del self[key]
            return value

        if default is not Blank:
            return default

        raise KeyError(key)

    def setdefault(self, key, default):
        if key in self:
            return self.__getitem__(key)

        self.__setitem__(key, default)
        return default

    def itervalues(self):
        getitem = self.__getitem__
        for key in self:
            yield getitem(key)

    def values(self):
        return list(self.itervalues())

    def iteritems(self):
        getitem = self.__getitem__
        for key in self:
            yield key, getitem(key)

    def items(self):
        return list(self.iteritems())

    def set_cache_size(self, cache_size):

        if not isinstance(cache_size, (int, long)):
            raise ValueError("Cache size must be an integer.")

        self._cache_size = cache_size

    def get_cache_byte_size(self):
        getitem = self.__getitem__
        return sum(len(str(getitem(key))) for key in self)

# ------------------------------------------------------------------------------
# Threaded Workers
# ------------------------------------------------------------------------------

URL_QUEUE = Queue()
GIT_QUEUE = Queue()
GAE_QUEUE = Queue()

EVENTS = {}

def threaded_worker_dispatcher(queue, error_logger=None):
    while 1:
        marker, worker, args, kwargs = queue.get()
        try:
            response = worker(*args, **kwargs)
        except Exception, error:
            EVENTS[marker] = (1, error)
        else:
            EVENTS[marker] = (0, response)

class Worker(object):

    def __init__(self, queue, callback, errback, func, args, kwargs):
        self.callback = callback
        self.errback = errback
        self.marker = marker = id(self)
        queue.put((marker, func, args, kwargs))
        Loop.add_callback(self.respond)

    def respond(self):
        marker = self.marker
        if marker not in EVENTS:
            Loop.add_callback(self.respond)
            return
        error, response = EVENTS.pop(marker)
        if error:
            self.errback(response)
        else:
            self.callback(response)

def worker(queue):
    def __worker(func):
        def wrapper(*args, **kwargs):
            def __wrapper(callback, errback):
                return Worker(queue, callback, errback, func, args, kwargs)
            __wrapper.__name__ = func.__name__
            return __wrapper
        wrapper.__name__ = func.__name__
        return wrapper
    return __worker

# ------------------------------------------------------------------------------
# Async Support
# ------------------------------------------------------------------------------

class TornadoWebDispatcher(object):
    """An async process dispatcher for tornado web handler methods."""

    cb = None

    def __init__(self, gen, handler):
        self.gen = gen
        self.handler = handler
        self.callback(None)

    def callback(self, arg=None, errback=None):
        try:
            if self.cb:
                self.cb(callback=self.callback, errback=self.errback)
                self.cb = None
                return
            if errback:
                self.cb = self.gen.throw(arg)
            else:
                self.cb = self.gen.send(arg)
            Loop.add_callback(self.callback)
        except StopIteration:
            self.cb = None
            if not self.handler._finished:
                self.handler.finish()
        except Exception, error:
            self.cb = None
            if self.handler._headers_written:
                logging.error('Exception after headers written', exc_info=True)
            else:
                self.handler._handle_request_exception(error)

    def errback(self, arg):
        self.callback(arg, errback=1)

def async(method):
    def wrapper(handler, *args, **kwargs):
        handler._auto_finish = 0
        TornadoWebDispatcher(method(handler, *args, **kwargs), handler)
    wrapper.__name__ = method.__name__
    return wrapper

def auth(async=False):
    def wrapper(method):
        def __wrapper(handler, *args, **kwargs):
            handler._auto_finish = 0
            TornadoWebDispatcher(
                authenticate(async, method, handler, *args, **kwargs), handler
                )
        __wrapper.__name__ = method.__name__
        return __wrapper
    return wrapper

def authenticate(async, method, handler, *args, **kwargs):
    login = handler.get_argument('login', '')
    if login:
        token = handler.get_argument('token', '')
        if login in USERS:
            if USERS[login] != token:
                raise HTTPError(403)
        info = yield get_github_user_info(login, token)
        if not info:
            raise HTTPError(403)
        redis = db()
        yield redis.set('login|%s' % login, encode_json(info))
    else:
        login = handler.get_secure_cookie('login')
        if not login:
            handler.redirect('/login')
            return
    if async:
        gen = method(handler, *args, **kwargs)
        resp = None
        # @@ this pipelining doesn't support catching exceptions downstream
        while 1:
            resp = yield gen.send(resp)
    else:
        method(handler, *args, **kwargs)

# ------------------------------------------------------------------------------
# Worker Functions
# ------------------------------------------------------------------------------

USERS = CachingDict()

@worker(URL_QUEUE)
def get_github_user_info(login, token, keys=['email', 'gravatar_id', 'name']):
    info = dict(login=login, token=token)
    url = "http://github.com/api/v2/json/user/show/%s?%s" % (
        quote(login), urlencode(info)
        )
    try:
        data = decode_json(urlopen(url).read())['user']
    except Exception:
        return
    if 'plan' not in data:
        return
    for key in keys:
        if key in data:
            info[key] = data[key]
    del info['login']
    USERS[login] = token
    return info

GAE_SERVICES = [
    'capability_service',
    'images',
    'mail',
    'memcache',
    'taskqueue',
    'urlfetch',
    'xmpp'
]

def _init_appengine(app_id, host, remote_key, secure, services=GAE_SERVICES):

    verifier = urlsafe_b64encode(urandom(24))
    mac = create_tamper_proof_string(
        'remote', verifier, duration=None, key=remote_key
        )

    path = '/.remote/%s' % mac
    environ['APPLICATION_ID'] = app_id

    server = NonAuthHttpRpcServer(
        host, None, GetUserAgent(), GetSourceName(), debug_data=False,
        secure=secure
        )

    apiproxy_stub_map.apiproxy = apiproxy_stub_map.APIProxyStubMap()
    datastore_stub = RemoteDatastoreStub(server, path)
    apiproxy_stub_map.apiproxy.RegisterStub('datastore_v3', datastore_stub)

    stub = RemoteStub(server, path)
    for service in services:
        apiproxy_stub_map.apiproxy.RegisterStub(service, stub)

def init_appengine(*args, **kwargs):
    marker = id(init_appengine)
    GAE_QUEUE.put((marker, _init_appengine, args, kwargs))
    while 1:
        if marker in EVENTS:
            break
        sleep(0.4)
    error, response = EVENTS.pop(marker)
    if error:
        raise response

@worker(GIT_QUEUE)
def apply_patch(repo, review_id, upstream, patch_file):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('am', '--abort')
    git('rebase', '--abort')
    git('clean', '-fdx', raise_error=True)
    git('reset', '--hard', 'HEAD', raise_error=True)
    for path in git('status', '--porcelain', raise_error=True).splitlines():
        if path.startswith('??'):
            path = path.split('??', 1)[1].strip()
            if isdir(path):
                rmtree(path)
    git('checkout', '-b', review_id, upstream, raise_error=True)
    git('am', patch_file, raise_error=True)
    git('push', 'origin', 'upstream/master:master', review_id, raise_error=True)

@worker(GIT_QUEUE)
def get_patch(repo, rev1, rev2):
    chdir(repo_paths[repo])
    git('diff', rev1, rev2)

@worker(GIT_QUEUE)
def get_new_commits(repo):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('push', 'origin', 'upstream/master:master', raise_error=True)
    return filter(None, git(
        'log', '--format="%H"', '%s...upstream/master' % LATEST[2],
        raise_error=True
        ).splitlines())

#%H %P %an %ae %t %cn %ce %ct %n %x01 %f %s

# ------------------------------------------------------------------------------
# Utility Functions
# ------------------------------------------------------------------------------

def git(*args, **kwargs):
    if kwargs.pop('raise_error', None):
        kwargs['retcode'] = True
        kwargs['reterror'] = True
        args = ['git'] + list(args)
        logging.error("Running: %s" % ' '.join(args))
        stdout, stderr, retcode = run_command(args, **kwargs)
        if retcode:
            raise RuntimeError(
                "Error running %s cwd=%s\n\n%s\n%s"
                % (' '.join(args), getcwd(), stdout, stderr)
                )
        return stdout
    if kwargs.pop('out', None):
        if 'exit_on_error' not in kwargs:
            kwargs['exit_on_error'] = True
        kwargs['redirect_stdout'] = False
        kwargs['redirect_stderr'] = False
        kwargs['retcode'] = True
    return run_command(['git'] + list(args), **kwargs)

def valid_review_id(id, valid=set('abcdefghijklmnopqrstuvwxyz0123456789-_')):
    if id.startswith('-') or id.startswith('_'):
        return
    for char in id:
        if char not in valid:
            return
    return id

# ------------------------------------------------------------------------------
# Datastore Models
# ------------------------------------------------------------------------------

class Foo(db.Model):

    bar = db.StringProperty()

# ------------------------------------------------------------------------------
# Git-related Functions
# ------------------------------------------------------------------------------

def update_repo(name):
    chdir(repo_paths[name])
    git('remote', 'update', '-p')
    git('push', 'origin', 'upstream/master:master')

# ------------------------------------------------------------------------------
# Handlers
# ------------------------------------------------------------------------------

class BaseHandler(RequestHandler):

    cache = None
    title = None

    def get_current_user(self):
        return self.get_secure_cookie('login')

    def is_admin_user(self):
        return self.current_user in settings['admins']

    def display(self, template, **kwargs):
        if 'errmsg' not in kwargs:
            kwargs['errmsg'] = None
        kwargs['is_admin'] = self.is_admin_user()
        if template:
            content = self.render_string(template + '.html', **kwargs)
        else:
            content = ''
        self.render('site.html', content=content, title=self.title, **kwargs)

class RootHandler(BaseHandler):

    def get(self):
        self.redirect('/activity')

class ActivityHandler(BaseHandler):

    def get(self):
        if not repos:
            self.display(None, errmsg='No repositories configured.')
            return
        self.display('home', repos=repos)

class BuildHandler(BaseHandler):

    def get(self):
        from random import random
        uname = self.get_argument('uname')
        repo_id = self.get_argument('repo_id')
        self.set_header('Content-Type', 'text/plain')
        if random() > 0.5:
            self.write('tav/ampify/master')
        else:
            self.write('//')

    def post(self):
        print decode_json(self.get_argument('data'))

class ReviewHandler(BaseHandler):

    def get(self):
        from random import random
        uname = self.get_argument('uname')
        repo_id = self.get_argument('repo_id')
        self.set_header('Content-Type', 'text/plain')
        if random() > 0.5:
            self.write('tav/ampify/master')
        else:
            self.write('//')

    @auth(async=True)
    def post(self):

        get = self.get_argument
        id = get('id')
        if not valid_review_id(id):
            self.write("Invalid characters in the review id: %s" % id)

        login = get('login')
        repo = get('repo')
        patch = get('patch')
        upstream = get('upstream')
        message = get('message', '')
        revision = get('revision')

        cc = get('cc', '')
        if cc:
            cc = decode_json(cc)
        else:
            cc = []

        login_id_prefix = '%s/%s' % (login, id)
        issue_number = 2
        review_id = '%s/%s/%s' % (login, id, issue_number)

        # existing_review_id = yield db.get(revision)
        # if existing_review_id:
        #     self.write(
        #         "This revision has already been submitted for review as %s."
        #         % existing_review_id
        #     )
        #     return

        fd, patch_file = mkstemp('-review-patch')
        write(fd, patch.encode('utf-8'))
        close(fd)

        yield apply_patch(repo, review_id, upstream, patch_file)

        self.write('OK %s' % review_id)
        #remove(patch_file)

class LoginHandler(BaseHandler):

    title = 'login'

    def get(self):
        self.display('login')

    @async
    def post(self):
        login = self.get_argument('login', "")
        token = self.get_argument('token', "")
        info = yield get_github_user_info(login, token)
        if not info:
            self.display('login', errmsg="Invalid Login.")
            return
        redis = db()
        yield redis.set('login|%s' % login, encode_json(info))
        self.set_secure_cookie('login', login)
        self.redirect('/')
        #errmsg='<img src="http://www.gravatar.com/avatar/%s" />' % info['gravatar_id']

class LogoutHandler(BaseHandler):

    def get(self):
        self.clear_cookie('login')
        return_to = self.get_argument('return_to', '')
        if return_to:
            self.redirect(return_to)
        else:
            self.redirect('/')

class SlavesHandler(BaseHandler):

    title = 'slaves'

    @async
    def get(self):
        self.display('slaves', slaves=[
            ['1', 'tav', 'Darwin 9.8.0 i386', '-', '2 hours and 41 minutes ago', 49],
            ['2', 'oierw', 'Linux 2.6.32-bpo.5-amd64 x86_64', '24 minutes ago', '-', 29]
            ], platforms=settings['platforms'])

    @auth(async=True)
    def post(self):
        self.display('slave-created')

class SlaveHandler(BaseHandler):

    title = 'slave'

    def get(self, slave_id):
        auth_user = self.current_user
        show_token = self.is_admin_user() # or ...
        slave_token = '086a83c7fce5ca77aa30acbe608eb02d6468'
        self.display(
            'slave',
            slave_id=slave_id,
            slave_token=slave_token,
            show_token=show_token
            )

    def post(self, slave_id):
        self.redirect('/slave/%s' % slave_id)

class PostReceiveHandler(BaseHandler):

    @async
    def post(self):
        commits = yield get_new_commits(self.get_argument('repo'))
        self.write('OK')

    get = post

# ------------------------------------------------------------------------------
# Main Runner
# ------------------------------------------------------------------------------

def main(argv=None):

    argv = argv or sys.argv[1:]
    op = OptionParser(
        usage="Usage: %prog [review-server.yaml]", version="0.1"
        )

    op.add_option('--debug', action='store_true', help="enable debug mode")
    op.add_option('--dev', action='store_true', help="enable dev mode")
    options, args = op.parse_args(argv)

    if args:

        config_path = args[0]
        config_file = open(config_path, 'rb')
        config_data = config_file.read()
        config_file.close()

        config = decode_yaml(config_data)
        if not config:
            print "ERROR: Couldn't find any config data in %s" % config_path
            sys.exit(1)

    else:
        config = {}

    settings.update(config)
    cwd = realpath(getcwd())

    if options.debug or options.dev:
        settings['debug'] = True
        cwd = dirname(realpath(__file__)) # to support autoreload

    for key in ['static_path', 'template_path', 'var_path']:
        path = join(cwd, settings[key])
        if not isdir(path):
            print "ERROR: Please create the %s: %s" % (key, path)
            sys.exit(1)
        settings[key] = path

    repo_home = settings['repo_home'] = join(settings['var_path'], 'repos')
    if not isdir(repo_home):
        print "ERROR: Please create %s" % repo_home
        sys.exit(1)

    github_account = settings['github_account']

    _repos = settings['repos']
    if _repos:
        for repo in _repos:
            repos[repo] = tuple(_repos[repo])
            repo_paths[repo] = repo_path = join(repo_home, repo)
            if options.dev:
                continue
            chdir(repo_home)
            if not isdir(repo_path):
                review_url = 'git@github.com:%s/%s.git' % (github_account, repo)
                git('clone', review_url, out=True)
            chdir(repo_path)
            if not git('config', 'remote.upstream.url', exit_on_error=False):
                upstream_url = 'https://github.com/%s/%s.git' % repos[repo]
                git('remote', 'add', 'upstream', upstream_url)
            git('remote', 'update', '-p', out=True)
            git('push', 'origin', 'upstream/master:master', out=True)

    application = Application([
        (r"/review", ReviewHandler),
        (r"/build", BuildHandler),
        (r"/logout", LogoutHandler),
        (r"/login", LoginHandler),
        (r"/slave/([0-9]+)", SlaveHandler),
        (r"/slaves", SlavesHandler),
        (r"/activity", ActivityHandler),
        (r"/post-receive", PostReceiveHandler),
        (r"/", RootHandler),
    ], **settings)

    http_server = HTTPServer(application)
    http_server.listen(settings['port'])

    set_max_connections(50)

    def cache_init(ipc=settings['redis_socket_file']):
        return Redis(unix_socket=ipc)

    global cache
    cache = cache_init

    for queue in [URL_QUEUE, GIT_QUEUE, GAE_QUEUE]:
        start_new_thread(threaded_worker_dispatcher, (queue,))

    init_appengine(
        settings['gae_app_id'], settings['gae_host'],
        settings['gae_remote_key'], settings['gae_secure']
        )

    print Foo.all().get()
    print "The git review server is listening on port %d ..." % settings['port']
    Loop.start()

# ------------------------------------------------------------------------------
# Self Runner
# ------------------------------------------------------------------------------

if __name__ == '__main__':
    main()
