#! /usr/bin/env python

# No Copyright (-) 2010 The Ampify Authors. This file is under the
# Public Domain license that can be found in the root LICENSE file.

"""Git review server."""

import logging
import sys

from base64 import urlsafe_b64encode
from binascii import hexlify
from hmac2 import HMAC
from optparse import OptionParser
from os import chdir, close, environ, getcwd, remove, urandom, write
from os.path import dirname, isdir, isfile, join, realpath
from Queue import Queue
from shutil import rmtree
from tempfile import mkstemp
from thread import start_new_thread
from time import sleep
from urllib import quote, urlencode, urlopen

from tornado.httpserver import HTTPServer
from tornado.web import Application, HTTPError, RequestHandler
from tornado.ioloop import IOLoop

from pyutil.crypto import create_tamper_proof_string, secure_string_comparison
from pyutil.env import run_command
from pyutil.redis import Redis, set_max_connections
from simplejson import loads as decode_json
from yaml import safe_load as decode_yaml

# ------------------------------------------------------------------------------
# Import Path
# ------------------------------------------------------------------------------

AMPIFY_ROOT = dirname(dirname(dirname(realpath(__file__))))
APP_ENGINE_SDK_PATH = join(AMPIFY_ROOT, '.appengine_python_sdk')

sys.path.insert(0, APP_ENGINE_SDK_PATH)
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'webob'))

from google.appengine.api import apiproxy_stub_map
from google.appengine.tools.appengine_rpc import HttpRpcServer
from google.appengine.ext import db
from google.appengine.ext.remote_api.remote_api_stub import (
    GetSourceName, GetUserAgent, RemoteDatastoreStub, RemoteStub
    )

class NonAuthHttpRpcServer(HttpRpcServer):
    def _DevAppServerAuthenticate(self):
        pass

# ------------------------------------------------------------------------------
# Settings
# ------------------------------------------------------------------------------

settings = dict(
    cookie_secret='insecure',
    debug=False,
    login_url='/login',
    port=8090,
    redis_socket_file='/tmp/review-server-cache.sock',
    repos=None,
    static_path='static',
    template_path='templates',
    var_path='var',
    xsrf_cookies=False
    )

Loop = IOLoop.instance()

repos = {}
repo_paths = {}

cache = None

# ------------------------------------------------------------------------------
# Cache
# ------------------------------------------------------------------------------

Blank = object()

class CachingDict(dict):
    """A caching dict that discards its least recently used items."""

    __slots__ = '_cache_size', '_garbage_collector', '_buffer_size', 'itersort', '_clock'

    def __init__(
        self, cache_size=1000, buffer_size=None, garbage_collector=None, *args,
        **kwargs
        ):

        self._cache_size = cache_size
        self._garbage_collector = garbage_collector
        self._buffer_size = buffer_size or cache_size / 2
        self._clock = 0

        for key, value in args:
            self.__setitem__(key, value)

        for key, value in kwargs.iteritems():
            self.__setitem__(key, value)

    def __setitem__(self, key, value):
        excess = len(self) - self._cache_size - self._buffer_size + 1
        if excess > 0:
            garbage_collector = self._garbage_collector
            # @@ time against : heapq.nsmallest()
            excess = sorted(self.itersort())[:excess + self._buffer_size]
            for ex_value, ex_key in excess:
                if garbage_collector:
                    garbage_collector(ex_key, ex_value)
                del self[ex_key]

        self._clock += 1
        return dict.__setitem__(self, key, [self._clock, value])

    def __getitem__(self, key):
        if key in self:
            access = dict.__getitem__(self, key)
            self._clock += 1
            access[0] = self._clock
            return access[1]

        raise KeyError(key)

    def itersort(self):
        getitem = dict.__getitem__
        for key in self:
            yield getitem(self, key), key

    def get(self, key, default=None):
        if key in self:
            return self.__getitem__(key)

        return default

    def pop(self, key, default=Blank):

        if key in self:
            value = dict.__getitem__(self, key)[1]
            del self[key]
            return value

        if default is not Blank:
            return default

        raise KeyError(key)

    def setdefault(self, key, default):
        if key in self:
            return self.__getitem__(key)

        self.__setitem__(key, default)
        return default

    def itervalues(self):
        getitem = self.__getitem__
        for key in self:
            yield getitem(key)

    def values(self):
        return list(self.itervalues())

    def iteritems(self):
        getitem = self.__getitem__
        for key in self:
            yield key, getitem(key)

    def items(self):
        return list(self.iteritems())

    def set_cache_size(self, cache_size):

        if not isinstance(cache_size, (int, long)):
            raise ValueError("Cache size must be an integer.")

        self._cache_size = cache_size

    def get_cache_byte_size(self):
        getitem = self.__getitem__
        return sum(len(str(getitem(key))) for key in self)

# ------------------------------------------------------------------------------
# Threaded Workers
# ------------------------------------------------------------------------------

URL_QUEUE = Queue()
GIT_QUEUE = Queue()
GAE_QUEUE = Queue()

EVENTS = {}

def threaded_worker_dispatcher(queue, error_logger=None):
    while 1:
        marker, worker, args, kwargs = queue.get()
        try:
            response = worker(*args, **kwargs)
        except Exception, error:
            EVENTS[marker] = (1, error)
        else:
            EVENTS[marker] = (0, response)

class Worker(object):

    def __init__(self, queue, callback, errback, func, args, kwargs):
        self.callback = callback
        self.errback = errback
        self.marker = marker = id(self)
        queue.put((marker, func, args, kwargs))
        Loop.add_callback(self.respond)

    def respond(self):
        marker = self.marker
        if marker not in EVENTS:
            Loop.add_callback(self.respond)
            return
        error, response = EVENTS.pop(marker)
        if error:
            self.errback(response)
        else:
            self.callback(response)

def worker(queue):
    def __worker(func):
        def wrapper(*args, **kwargs):
            def __wrapper(callback, errback):
                return Worker(queue, callback, errback, func, args, kwargs)
            __wrapper.__name__ = func.__name__
            return __wrapper
        wrapper.__name__ = func.__name__
        return wrapper
    return __worker

# ------------------------------------------------------------------------------
# Async Support
# ------------------------------------------------------------------------------

class TornadoWebDispatcher(object):
    """An async process dispatcher for tornado web handler methods."""

    cb = None

    def __init__(self, gen, handler):
        self.gen = gen
        self.handler = handler
        self.callback(None)

    def callback(self, arg=None, errback=None):
        try:
            if self.cb:
                self.cb(callback=self.callback, errback=self.errback)
                self.cb = None
                return
            if errback:
                self.cb = self.gen.throw(arg)
            else:
                self.cb = self.gen.send(arg)
            Loop.add_callback(self.callback)
        except StopIteration:
            self.cb = None
            if not self.handler._finished:
                self.handler.finish()
        except Exception, error:
            self.cb = None
            if self.handler._headers_written:
                logging.error('Exception after headers written', exc_info=True)
            else:
                self.handler._handle_request_exception(error)

    def errback(self, arg):
        self.callback(arg, errback=1)

def async(method):
    def wrapper(handler, *args, **kwargs):
        handler._auto_finish = 0
        TornadoWebDispatcher(method(handler, *args, **kwargs), handler)
    wrapper.__name__ = method.__name__
    return wrapper

# ------------------------------------------------------------------------------
# Auth Support
# ------------------------------------------------------------------------------

def auth(async=False, cookie=True, xsrf=False):
    def wrapper(method):
        def __wrapper(handler, *args, **kwargs):
            handler._auto_finish = 0
            TornadoWebDispatcher(
                authenticate(
                    async, method, handler, cookie, xsrf, *args, **kwargs
                    ),
                handler
                )
        __wrapper.__name__ = method.__name__
        return __wrapper
    return wrapper

def authenticate(async, method, handler, cookie, xsrf, *args, **kwargs):
    login = handler.get_argument('login', '')
    if login:
        token = handler.get_argument('token', '')
        if login in USERS:
            if not secure_string_comparison(USERS[login], token):
                raise HTTPError(403)
        info = yield get_github_user_info(login, token)
        if not info:
            raise HTTPError(403)
        yield update_user(login, info)
        USERS[login] = token
    elif cookie:
        login = handler.get_secure_cookie('login')
        if not login:
            handler.redirect('/login')
            return
    else:
        raise HTTPError(403)
    if xsrf:
        xsrf_token = handler.get_argument('xsrf_token', '')
        if not xsrf_token:
            raise HTTPError(403)
        if login not in XSRF:
            XSRF[login] = HMAC(settings['xsrf_secret'], login).hexdigest()
        if not secure_string_comparison(XSRF[login], xsrf_token):
            raise HTTPError(403)
    if async:
        gen = method(handler, *args, **kwargs)
        resp = None
        # @@ this pipelining doesn't support catching exceptions downstream
        while 1:
            resp = yield gen.send(resp)
    else:
        method(handler, *args, **kwargs)

# ------------------------------------------------------------------------------
# Utility Functions
# ------------------------------------------------------------------------------

def git(*args, **kwargs):
    if kwargs.pop('raise_error', None):
        kwargs['retcode'] = True
        kwargs['reterror'] = True
        args = ['git'] + list(args)
        logging.error("Running: %s" % ' '.join(args))
        stdout, stderr, retcode = run_command(args, **kwargs)
        if retcode:
            raise RuntimeError(
                "Error running %s cwd=%s\n\n%s\n%s"
                % (' '.join(args), getcwd(), stdout, stderr)
                )
        return stdout
    if kwargs.pop('out', None):
        if 'exit_on_error' not in kwargs:
            kwargs['exit_on_error'] = True
        kwargs['redirect_stdout'] = False
        kwargs['redirect_stderr'] = False
        kwargs['retcode'] = True
    return run_command(['git'] + list(args), **kwargs)

def valid_review_id(id, valid=set('abcdefghijklmnopqrstuvwxyz0123456789-_')):
    if id.startswith('-') or id.startswith('_'):
        return
    for char in id:
        if char not in valid:
            return
    return id

def update_repo(name):
    chdir(repo_paths[name])
    git('remote', 'update', '-p')
    git('push', 'origin', 'upstream/master:master')

# ------------------------------------------------------------------------------
# Worker Functions
# ------------------------------------------------------------------------------

USERS = CachingDict()
XSRF = CachingDict()

@worker(URL_QUEUE)
def get_github_user_info(login, token, keys=['email', 'gravatar_id', 'name']):
    info = dict(login=login, token=token)
    url = "http://github.com/api/v2/json/user/show/%s?%s" % (
        quote(login), urlencode(info)
        )
    try:
        data = decode_json(urlopen(url).read())['user']
    except Exception:
        return
    if 'plan' not in data:
        return
    for key in keys:
        if key in data:
            info[key] = data[key]
    return info

GAE_SERVICES = [
    'capability_service',
    'images',
    'mail',
    'memcache',
    'taskqueue',
    'urlfetch',
    'xmpp'
]

def _init_appengine(app_id, host, remote_key, secure, services=GAE_SERVICES):

    verifier = urlsafe_b64encode(urandom(24))
    mac = create_tamper_proof_string(
        'remote', verifier, duration=None, key=remote_key
        )

    path = '/.remote/%s' % mac
    environ['APPLICATION_ID'] = app_id

    server = NonAuthHttpRpcServer(
        host, None, GetUserAgent(), GetSourceName(), debug_data=False,
        secure=secure
        )

    apiproxy_stub_map.apiproxy = apiproxy_stub_map.APIProxyStubMap()
    datastore_stub = RemoteDatastoreStub(server, path)
    apiproxy_stub_map.apiproxy.RegisterStub('datastore_v3', datastore_stub)

    stub = RemoteStub(server, path)
    for service in services:
        apiproxy_stub_map.apiproxy.RegisterStub(service, stub)

def init_appengine(*args, **kwargs):
    marker = id(init_appengine)
    GAE_QUEUE.put((marker, _init_appengine, args, kwargs))
    while 1:
        if marker in EVENTS:
            break
        sleep(0.4)
    error, response = EVENTS.pop(marker)
    if error:
        raise response

@worker(GIT_QUEUE)
def apply_patch(repo, review_id, upstream, patch_file):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('am', '--abort')
    git('rebase', '--abort')
    git('clean', '-fdx', raise_error=True)
    git('reset', '--hard', 'HEAD', raise_error=True)
    for path in git('status', '--porcelain', raise_error=True).splitlines():
        if path.startswith('??'):
            path = path.split('??', 1)[1].strip()
            if isdir(path):
                rmtree(path)
    git('checkout', '-b', review_id, upstream, raise_error=True)
    git('am', patch_file, raise_error=True)
    git('push', 'origin', 'upstream/master:master', review_id, raise_error=True)

@worker(GIT_QUEUE)
def get_patch(repo, rev1, rev2):
    chdir(repo_paths[repo])
    git('diff', rev1, rev2)

@worker(GIT_QUEUE)
def get_new_commits(repo):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('push', 'origin', 'upstream/master:master', raise_error=True)
    return filter(None, git(
        'log', '--format="%H"', '%s...upstream/master' % LATEST[2],
        raise_error=True
        ).splitlines())

#%H %P %an %ae %t %cn %ce %ct %n %x01 %f %s

@worker(GAE_QUEUE)
def update_user(login, info):
    user = User.get_or_insert(login)
    user.token = str(info['token'])
    user.gravatar = info['gravatar_id']
    user.name = info.get('name', '')
    user.emails = [info['email']]
    user.put()

@worker(GAE_QUEUE)
def create_slave(owner):
    slave = Slave()
    slave.owner = owner
    slave.token = hexlify(urandom(18))
    slave.put()
    return slave.key().id()

@worker(GAE_QUEUE)
def reset_slave_token(slave_id, user, is_admin):
    slave = Slave.get_by_id(int(slave_id))
    if not slave:
        return
    if is_admin or user == slave.owner:
        slave.token = hexlify(urandom(18))
        slave.put()
        return 1
    return 2

# ------------------------------------------------------------------------------
# Datastore Models
# ------------------------------------------------------------------------------

class B(db.Model):
    slave = db.IntegerProperty(name='s')
    repo = db.ByteStringProperty(name='r')
    version = db.StringProperty(name='v')
    uname = db.StringProperty(name='u')
    executed = db.StringListProperty(name='e')
    payload = db.TextProperty(name='p') # timings and failures
    has_failure = db.BooleanProperty(name='h', default=False)
    date = db.DateTimeProperty(name='d', auto_now_add=True)

Build = B

class C(db.Model):
    user = db.StringProperty(name='u')
    date = db.DateTimeProperty(name='d', auto_now_add=True)

Comment = C

class G(db.Model):
    author = db.StringProperty(name='a')
    author_email = db.StringProperty(name='b')
    committer = db.StringProperty(name='c')
    committer_email = db.StringProperty(name='e')
    committed_timestamp = db.DateTimeProperty(name='t')
    subject = db.TextProperty(name='s')
    repo = db.ByteStringProperty(name='r')
    version = db.ByteStringProperty(name='v')
    passed_unames = db.StringListProperty(name='p')
    failed_unames = db.StringListProperty(name='f')
    has_failure = db.BooleanProperty(name='h', default=False)
    user = db.StringProperty(name='u') # #unknown
    date = db.DateTimeProperty(name='d', auto_now_add=True)

Commit = G

class P(db.Model):
    slave = db.IntegerProperty(name='s')
    job = db.StringProperty(name='j')
    date = db.DateTimeProperty(name='d', auto_now_add=True)

PendingJob = P

class Q(db.Model):
    review = db.ByteStringProperty(name='r')
    counter = db.IntegerProperty(name='c', default=0)

ReviewCounter = Q

class R(db.Model):
    subject = db.TextProperty(name='s')
    repo = db.ByteStringProperty(name='r')
    version = db.IntegerProperty(name='v')
    passed_unames = db.StringListProperty(name='p')
    failed_unames = db.StringListProperty(name='f')
    has_failure = db.BooleanProperty(name='h', default=False)
    user = db.StringProperty(name='u')
    date = db.DateTimeProperty(name='d', auto_now_add=True)

Review = R

class S(db.Model):
    disabled = db.BooleanProperty(name='d', default=False)
    token = db.ByteStringProperty(name='t')
    owner = db.StringProperty(name='o')
    last_seen = db.DateTimeProperty(name='l')
    recent_platform = db.StringProperty(name='r')
    jobs_done = db.IntegerProperty(name='j', default=0)

Slave = S

class U(db.Model):
    name = db.StringProperty(name='n')
    gravatar = db.ByteStringProperty(name='g')
    emails = db.StringListProperty(name='e')
    token = db.ByteStringProperty(name='t')
    last_seen = db.DateTimeProperty(name='l', auto_now=True)

User = U

# ------------------------------------------------------------------------------
# Handlers
# ------------------------------------------------------------------------------

class BaseHandler(RequestHandler):

    cache = None
    title = None

    def get_current_user(self):
        return self.get_secure_cookie('login')

    def is_admin_user(self):
        return self.current_user in settings['admins']

    def display(self, template, **kwargs):
        if 'errmsg' not in kwargs:
            kwargs['errmsg'] = None
        kwargs['is_admin'] = self.is_admin_user()
        user = self.current_user
        if user:
            if user not in XSRF:
                XSRF[user] = HMAC(settings['xsrf_secret'], user).hexdigest()
            kwargs['xsrf_token'] = XSRF[user]
        else:
            kwargs['xsrf_token'] = None
        if template:
            content = self.render_string(template + '.html', **kwargs)
        else:
            content = ''
        self.render('site.html', content=content, title=self.title, **kwargs)

class RootHandler(BaseHandler):

    def get(self):
        self.redirect('/activity')

class ActivityHandler(BaseHandler):

    def get(self):
        if not repos:
            self.display(None, errmsg='No repositories configured.')
            return
        self.display('home', repos=repos)

class BuildHandler(BaseHandler):

    def get(self):
        from random import random
        uname = self.get_argument('uname')
        repo_id = self.get_argument('repo_id')
        self.set_header('Content-Type', 'text/plain')
        if random() > 0.5:
            self.write('tav/ampify/master')
        else:
            self.write('//')

    def post(self):
        print decode_json(self.get_argument('data'))

class ReviewHandler(BaseHandler):

    def get(self):
        from random import random
        uname = self.get_argument('uname')
        repo_id = self.get_argument('repo_id')
        self.set_header('Content-Type', 'text/plain')
        if random() > 0.5:
            self.write('tav/ampify/master')
        else:
            self.write('//')

    @auth(async=True)
    def post(self):

        get = self.get_argument
        id = get('id')
        if not valid_review_id(id):
            self.write("Invalid characters in the review id: %s" % id)

        login = get('login')
        repo = get('repo')
        patch = get('patch')
        upstream = get('upstream')
        message = get('message', '')
        revision = get('revision')

        cc = get('cc', '')
        if cc:
            cc = decode_json(cc)
        else:
            cc = []

        login_id_prefix = '%s/%s' % (login, id)
        issue_number = 2
        review_id = '%s/%s/%s' % (login, id, issue_number)

        # existing_review_id = yield db.get(revision)
        # if existing_review_id:
        #     self.write(
        #         "This revision has already been submitted for review as %s."
        #         % existing_review_id
        #     )
        #     return

        fd, patch_file = mkstemp('-review-patch')
        write(fd, patch.encode('utf-8'))
        close(fd)

        yield apply_patch(repo, review_id, upstream, patch_file)

        self.write('OK %s' % review_id)
        #remove(patch_file)

class LoginHandler(BaseHandler):

    title = 'login'

    def get(self):
        self.display('login')

    @async
    def post(self):
        login = self.get_argument('login', "")
        token = self.get_argument('token', "")
        info = yield get_github_user_info(login, token)
        if not info:
            self.display('login', errmsg="Invalid Login.")
            return
        yield update_user(login, info)
        USERS[login] = token
        self.set_secure_cookie('login', login)
        self.redirect('/')

class LogoutHandler(BaseHandler):

    def get(self):
        self.clear_cookie('login')
        return_to = self.get_argument('return_to', '')
        if return_to:
            self.redirect(return_to)
        else:
            self.redirect('/')

class SlavesHandler(BaseHandler):

    title = 'slaves'

    @async
    def get(self):
        self.display('slaves', slaves=[
            ['1', 'tav', 'Darwin 9.8.0 i386', '-', '2 hours and 41 minutes ago', 49],
            ['2', 'oierw', 'Linux 2.6.32-bpo.5-amd64 x86_64', '24 minutes ago', '-', 29]
            ], platforms=settings['platforms'])

    @auth(async=True, xsrf=True)
    def post(self):
        slave_id = yield create_slave(self.current_user)
        invalidate_cache('slaves')
        self.redirect('/slave/%s' % slave_id)

class SlaveHandler(BaseHandler):

    title = 'slave'

    def get(self, slave_id):
        auth_user = self.current_user
        show_token = self.is_admin_user() # or ...
        slave_token = '086a83c7fce5ca77aa30acbe608eb02d6468'
        self.display(
            'slave',
            slave_id=slave_id,
            slave_token=slave_token,
            show_token=show_token
            )

    @auth(async=True, xsrf=True)
    def post(self, slave_id):
        retcode = yield reset_slave_token(
            slave_id, self.current_user, self.is_admin_user()
            )
        if not retcode:
            self.display(
                None, errmsg="Couldn't find a record for slave %s." % slave_id
                )
            return
        if retcode == 2:
            self.display(None, errmsg="You're not the owner of this slave.")
            return
        self.redirect('/slave/%s' % slave_id)

class PostReceiveHandler(BaseHandler):

    @async
    def post(self):
        commits = yield get_new_commits(self.get_argument('repo'))
        self.write('OK')

    get = post

# ------------------------------------------------------------------------------
# Main Runner
# ------------------------------------------------------------------------------

def main(argv=None):

    argv = argv or sys.argv[1:]
    op = OptionParser(usage="Usage: %prog [config.yaml]", version="0.1")

    op.add_option('--dev', action='store_true', help="enable dev mode")
    options, args = op.parse_args(argv)

    if args:
        config_path = args[0]
        config_file = open(config_path, 'rb')
        config_data = config_file.read()
        config_file.close()
        config = decode_yaml(config_data)
        if not config:
            print "ERROR: Couldn't find any config data in %s" % config_path
            sys.exit(1)
    else:
        config = {}

    settings.update(config)
    cwd = realpath(getcwd())

    if options.dev:
        settings['debug'] = True
        cwd = dirname(realpath(__file__)) # @@ to support autoreload

    for key in ['static_path', 'template_path', 'var_path']:
        path = join(cwd, settings[key])
        if not isdir(path):
            print "ERROR: Please create the %s: %s" % (key, path)
            sys.exit(1)
        settings[key] = path

    repo_home = settings['repo_home'] = join(settings['var_path'], 'repos')
    if not isdir(repo_home):
        print "ERROR: Please create %s" % repo_home
        sys.exit(1)

    github_account = settings['github_account']

    _repos = settings['repos']
    if _repos:
        for repo in _repos:
            repos[repo] = tuple(_repos[repo])
            repo_paths[repo] = repo_path = join(repo_home, repo)
            if options.dev:
                continue
            chdir(repo_home)
            if not isdir(repo_path):
                review_url = 'git@github.com:%s/%s.git' % (github_account, repo)
                git('clone', review_url, out=True)
            chdir(repo_path)
            if not git('config', 'remote.upstream.url', exit_on_error=False):
                upstream_url = 'https://github.com/%s/%s.git' % repos[repo]
                git('remote', 'add', 'upstream', upstream_url)
            git('remote', 'update', '-p', out=True)
            git('push', 'origin', 'upstream/master:master', out=True)

    application = Application([
        (r"/review", ReviewHandler),
        (r"/build", BuildHandler),
        (r"/logout", LogoutHandler),
        (r"/login", LoginHandler),
        (r"/slave/([0-9]+)", SlaveHandler),
        (r"/slaves", SlavesHandler),
        (r"/activity", ActivityHandler),
        (r"/post-receive", PostReceiveHandler),
        (r"/", RootHandler),
    ], **settings)

    http_server = HTTPServer(application)
    http_server.listen(settings['port'])

    set_max_connections(50)

    def cache_init(ipc=settings['redis_socket_file']):
        return Redis(unix_socket=ipc)

    global cache
    cache = cache_init

    for queue in [URL_QUEUE, GIT_QUEUE, GAE_QUEUE]:
        start_new_thread(threaded_worker_dispatcher, (queue,))

    print "Connecting to App Engine Server at", settings['gae_host']
    init_appengine(
        settings['gae_app_id'], settings['gae_host'],
        settings['gae_remote_key'], settings['gae_secure']
        )

    print "The git review server is listening on port %d ..." % settings['port']
    Loop.start()

# ------------------------------------------------------------------------------
# Self Runner
# ------------------------------------------------------------------------------

if __name__ == '__main__':
    main()

# <img src="http://www.gravatar.com/avatar/%s" />
